'use client'
import Image from 'next/image'
import imgBostrom from '@/assets/images/bostrom.jpg'
import imgMusk from '@/assets/images/musk-3.jpg'
import imgKurzweil from '@/assets/images/kurzweil.jpg'
import Link from 'next/link'

export default function Home() {

  return (
    <>
      <h1>Will Humanity Outlive Its *Final&nbsp;Invention*?</h1>
      <h2>Почему всё так <span className='accent'>изменилось</span></h2>
        <p>
          После появления ChatGPT в конце 2022 г. ИИ перестал быть научной
          фантастикой. Практически никто из специалистов, работающих над
          проблемой ИИ, уже не сомневается, что машины, способные думать на
          человеческом уровне и даже превосходящем его, будут созданы.
        </p>
        <p>
          <Image
            alt="Bostrom"
            title='Nick Bøstrom, "Superintelligence: Paths, Dangers, Strategies"'
            src={imgBostrom}
            width="394"
            className="float-to-right obscured"
          />
          ИИ, достигший такого уровня развития, называют Суперинтеллектом. Этот
          термин популяризировал шведский философ Н. Бостром в своей книге 2014
          г. <em><strong>Superintelligence: Paths, Dangers, Strategies</strong></em>. Он и множество
          других мыслителей считают, что Суперинтеллект будет способен к
          рекурсивному самоулучшению, и этот процесс будет невозможно
          контролировать извне.
          <Link href="#soon" className="tell-me-more">Подробнее…</Link>
        </p>
        <p>
          Когда будет создан ИИ такого рода, пока неизвестно, однако скорость, с
          которой развивается эта область НТП, предполагает, что для этого
          потребуются уже не десятилетия, но годы.
        </p>
        <h2>В чём здесь <span className='accent'>проблема?</span></h2>
        <p>
          Проблема здесь в том, что мы можем создать сущность, более
          могущественную чем мы сами и при этом обладающую целями, отличающимися
          от наших. Это значит, что существование человечества может оказаться в
          зависимости от её намерений. Если эти намерения будут дружественными,
          Суперинтеллект может стать нашим партнёром. Это позволит нам решить
          наши наиболее серьёзные проблемы, над которыми человечество бьётся
          тысячелетиями. Возможно, изменится сама форма нашего существования,
          превратившись в <Link href="#soon" className="regular">симбиотическое сосуществование</Link> искусственного и
          человеческого разумов. Это откроет для нас перспективы постижения
          вселенной на уровне, который мы сейчас не можем себе вообразить. Хотя
          невозможно предвидеть, каким будет это будущее, нашей главной надеждой
          является здесь то, что оно будет предметом нашего желания и выбора.
        </p>
        <p>
          В случае худшего сценария мы исчезнем с исторической сцены как вид. Мы
          можем оказаться не нужными этой сверхмогущественной сущности. Может
          статься, что мы, в соответствии с опасением Илона Маска, просто
          окажемся в роли биологического загрузчика для Суперинтеллекта. Тем
          самым, он может оказаться тем, что журналист и писатель Дж. Баррат
          назвал «Нашим последним изобретением» в своей книге 2013 г. Our Final
          Invention: Artificial Intelligence and the End of the Human Era.
        </p>
        
        <h2><Image
          alt="Musk"
          title='Elon Musk'
          src={imgMusk}
          width="430"
          className="float-to-left obscured"
        />
        Почему мы <span className='accent'>не сможем предотвратить</span> создание Суперинтеллекта</h2>
        <p>
          Фундаментальный аспект этой проблемы состоит в том, что мы не сможем
          отказаться от создания этой сущности. Замедлить этот процесс также
          весьма сложно. Тому есть несколько объективных причин. Мы подробно
          анализируем их в <Link href="/why-we-will-not-refuse">следующем разделе</Link>. Здесь же остановимся на наиболее очевидных,
          каковыми являются: 1)&nbsp;рыночный спрос на ИИ, 2)&nbsp;бизнес-приоритеты
          разработчиков ИИ, 3)&nbsp;геополитическое соперничество государств,
          способных создать ИИ и 4)&nbsp;трудности контроля за незаконной разработкой
          ИИ.
        </p>
        <h3>1. Рыночный спрос на ИИ-продукты</h3>
        <p>
          Востребованность ИИ означает ИИ-гонку. Регулировать этот процесс
          чрезвычайно сложно, поскольку общественная осведомлённость о проблеме
          отстаёт от динамики её развития. Это затрудняет принятие эффективных
          политических решений в данной области.
          <Link href="#" className="tell-me-more">Подробнее…</Link>
        </p>
        <h3>2. Бизнес-приоритеты разработчиков ИИ</h3>
        <p>
          Компании-разработчики ИИ прежде всего заинтересованы в получении
          прибыли, а не в обеспечении безопасности своих продуктов. Это
          побуждает их приносить второе в жертву первому. Даже, если они
          осознают возможные последствия такого подхода, им трудно принимать
          взвешенные решения из-за конкурентного давления.
          <Link href="#" className="tell-me-more">Подробнее…</Link>
        </p>
        <h3>
          3. Геополитическое соперничество государств, способных создать
          Суперинтеллект
        </h3>
        <p>
          Режим, нетерпимый к своим идеологическим оппонентам, такой, как
          Китайский или Российский, может оказаться перед соблазном применить ИИ
          для их устранения. Их противники, в свою очередь, будут принимать
          ответные меры. Тем самым, ИИ-гонка может быть эскалирована до
          международного уровня. Это не только затруднит решение проблемы
          безопасного ИИ, но существенно усложнит её.
        </p>
        <p>
          Формальное согласие сторон не использовать ИИ как оружие может
          оказаться неэффективным. Для его соблюдения требуется прозрачность не
          только намерений сторон, но и состояния их разработок. Это трудно
          контролировать технически и институционально из-за столкновения
          интересов различных сил внутри самих обществ.
          <Link href="#" className="tell-me-more">Подробнее…</Link>
        </p>
        <h3>4. Трудности контроля за незаконной разработкой ИИ</h3>
        <p>
          Наконец, частные разработчики, включая злонамеренных, могут
          разрабатывать ИИ вне всякого внешнего контроля. Для этого не нужно
          создание какой-либо особенной инфраструктуры, организации сверхсложных
          производственных или логистических процессов. По большей части это —
          вопрос доступа к знаниям и разработки ПО, что в современных условиях
          вполне осуществимо при наличии даже относительно скромного
          финансирования. Очевидно что для таких разработчиков безопасность не
          будет являться приоритетом. Т.о., последствия легко могут оказаться
          непреднамеренными для них самих и стать катастрофическими для всего
          человечества.
          <Link href="#" className="tell-me-more">Подробнее…</Link>
        </p>
        <h2>
          Приближаясь к <span className='accent'>точке невозврата</span>
          <Image
            alt="kurzweil"
            title='Ray Kurzweil "The Singularity is Near"'
            src={imgKurzweil}
            width="500"
            className="float-to-right obscured"
          />
        </h2>

        <p>
          Итак, у нас есть основания полагать, что мы приближаемся к событию,
          которое можно будет назвать точкой невозврата в истории человечества.
          Создание Суперинтеллекта вызовет то, что британский математик И. Дж.
          Гуд ещё в середине 60-х гг. 20 века определил как «взрыв интеллекта» .
          В то время это выглядело неопределённо далекой или вовсе нереальной
          перспективой. Но сейчас это уже не так. Знаменитый изобретатель,
          писатель-футуролог, Principal Researcher и AI Visionary в Google Р.
          Курцвейл в своей нашумевшей книге The Singularity Is Near: When Humans
          Transcend Biology (2005) предсказывал создание Суперинтеллекта около
          2045 и его прогноз сейчас является далеко не самым радикальным. Если
          это, действительно, произойдёт, впервые в истории земли на ней
          окажется более одного разумного вида, и один из них будет многократно
          превосходить другой в своих когнитивных способностях.
        </p>
        <p>
          Неприятное допущение из этого заключается в том, что у нас нет
          гарантии выживания. Горизонт нашего планирования в отношении
          Суперинтеллекта весьма ограничен. В уравнении новой реальности гораздо
          больше неизвестных переменных чем тех, которыми мы можем оперировать.
          Пока что у нас нет надёжных подходов, позволяющих предсказать его
          намерения и обезопасить себя от тех, которые могут представлять для
          нас угрозу. Тем самым мы должны осознать, что если мы не сумеем
          разработать такие подходы, всё может пойти по худшему для нас
          сценарию.
        </p>
        <p>
          Хорошая новость состоит в том, что человечество располагает множеством
          блестящих умов, готовых работать над этим вопросом, огромными знаниями
          и опытом успешного решения невероятно сложных проблем. Конечно,
          проблема Суперинтеллекта экстраординарна во всех смыслах, но это не
          значит, что она нерешаема в принципе. К тому же наш ум обладает
          спасительной особенностью максимальной мобилизации своих ресурсов в
          ситуациях экзистенциального вызова.
        </p>
        <p>
          Возможно, что преодоление вызова, стоящего за проблемой
          Суперинтеллекта, более всего зависит от нашей способности осознать его
          актуальность.
        </p>
        <p>
          Поэтому мы призываем всех, кому не безразлично будущее человечества,
          отнестись к информации, изложенной на этом сайте как можно более
          серьёзно и сделать посильный вклад в решение важнейшей проблемы,
          стоящей перед человечеством. Чтобы помочь вам разобраться в сущности
          этой проблемы, мы предлагаем вам начать с того, чтобы:
        </p>
        <ul>
          <li>
            углубиться в понимание человеческой мотивации в создании
            Суперинтеллекта
          </li>
          <li>
            рассмотреть возможные сценарии развития событий уже в ближайшие годы
          </li>
          <li>
            познакомиться с текущими подходами в решении проблемы
            Суперинтеллекта
          </li>
          <li>
            взглянуть на проблему взаимоотношений человеческого разума и ИИ
            сквозь инсайты великих визионеров.
          </li>
        </ul>
        <p>Удачи в вашем исследовании!</p>
    </>
  )
}